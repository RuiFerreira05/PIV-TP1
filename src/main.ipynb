{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf37b19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.spatial.distance as spd\n",
    "import psColor, bwLabel\n",
    "import os\n",
    "\n",
    "# Load training dataset\n",
    "TRAIN_DIR = os.listdir(path='../data/treino')\n",
    "DATA = [cv2.imread('../data/treino/' + image_path) for image_path in TRAIN_DIR]\n",
    "\n",
    "print(f\"Number of images in training set: {len(DATA)}\")\n",
    "print(f\"Image shape: {DATA[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7310aa4",
   "metadata": {},
   "source": [
    "## 1. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4178115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImages(imageArray, titles):\n",
    "    \"\"\"Display de images com OpenCV.\"\"\"\n",
    "    for i, img in enumerate(imageArray):\n",
    "        cv2.imshow(titles[i], img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def pltImages(imageArray, titles, cmap=None):\n",
    "    \"\"\"Display de imagens com Matplotlib subplots.\"\"\"\n",
    "    n_images = len(imageArray)\n",
    "    for i, image in enumerate(imageArray):\n",
    "        plt.subplot(n_images, 1, i + 1)\n",
    "        plt.imshow(image, cmap=cmap)\n",
    "        plt.title(titles[i])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adc601b",
   "metadata": {},
   "source": [
    "## 2. Processamento de Imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb38431b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarizacao(image, tolerance):\n",
    "    \"\"\"\n",
    "    Perform image binarization to highlight objects by removing the background.\n",
    "    \n",
    "    Args:\n",
    "        image (np.array): BGR image array to be binarized\n",
    "        tolerance (int): Tolerance for calculating the background color range\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (image_objects, bin_image)\n",
    "            - image_objects: RGB image without background\n",
    "            - bin_image: Binary image\n",
    "    \"\"\"\n",
    "    # Calculate histogram for each color channel\n",
    "    hist_blue = cv2.calcHist([image], [0], None, [256], [0, 256])\n",
    "    max_blue_idx = np.argmax(hist_blue)\n",
    "    low_blue = max_blue_idx - tolerance\n",
    "    high_blue = max_blue_idx + tolerance\n",
    "\n",
    "    hist_green = cv2.calcHist([image], [1], None, [256], [0, 256])\n",
    "    max_green_idx = np.argmax(hist_green)\n",
    "    low_green = max_green_idx - 60\n",
    "    high_green = max_green_idx + 60\n",
    "\n",
    "    hist_red = cv2.calcHist([image], [2], None, [256], [0, 256])\n",
    "    max_red_idx = np.argmax(hist_red)\n",
    "    low_red = max_red_idx - 40\n",
    "    high_red = max_red_idx + 40\n",
    "\n",
    "    # Define color range for background\n",
    "    low_color = np.array([low_blue, low_green, low_red])\n",
    "    high_color = np.array([high_blue, high_green, high_red])\n",
    "    \n",
    "    # Remove background\n",
    "    background_mask = cv2.inRange(image, low_color, high_color)\n",
    "    inverted_mask = 255 - background_mask\n",
    "    image_objects = cv2.bitwise_and(image, image, mask=inverted_mask)\n",
    "    \n",
    "    # Convert to grayscale and apply Otsu's thresholding\n",
    "    image_gs = cv2.cvtColor(image_objects, cv2.COLOR_BGR2GRAY)\n",
    "    _, bin_image = cv2.threshold(image_gs, 0, 255, cv2.THRESH_OTSU)\n",
    "    \n",
    "    return image_objects, bin_image\n",
    "\n",
    "def optimize_image(image):\n",
    "    \"\"\"\n",
    "    Apply morphological operations to improve binary image quality.\n",
    "    \n",
    "    Args:\n",
    "        image (np.array): Binary image to optimize\n",
    "        \n",
    "    Returns:\n",
    "        np.array: Optimized binary image\n",
    "    \"\"\"\n",
    "    image_opt = image\n",
    "    \n",
    "    # Close small gaps\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15, 15))\n",
    "    image_opt = cv2.morphologyEx(image_opt, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # Erode to separate touching objects\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (50, 50))\n",
    "    image_opt = cv2.morphologyEx(image_opt, cv2.MORPH_ERODE, kernel)\n",
    "    \n",
    "    # Dilate to restore object size to approximate original\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (25, 25))\n",
    "    image_opt = cv2.morphologyEx(image_opt, cv2.MORPH_DILATE, kernel)\n",
    "    \n",
    "    return image_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de642de9",
   "metadata": {},
   "source": [
    "## 3. Extração de Componentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01ca618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contours(img):\n",
    "    \"\"\"Extract contours from an image.\"\"\"\n",
    "    _, bin_img = binarizacao(img, 110)\n",
    "    opt_img = optimize_image(bin_img)\n",
    "    contours, _ = cv2.findContours(opt_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "\n",
    "def get_propriedades_container(container):\n",
    "    \"\"\"\n",
    "    Extract geometric properties from a list of contours.\n",
    "    \n",
    "    Properties extracted:\n",
    "    - Area\n",
    "    - Perimeter\n",
    "    - Circularity\n",
    "    - Delta (difference between min area rect and actual area)\n",
    "    - Proportion (width/height ratio)\n",
    "    \n",
    "    Args:\n",
    "        container (list): List of contours\n",
    "        \n",
    "    Returns:\n",
    "        np.array: Array of shape (n_contours, 5) containing properties\n",
    "    \"\"\"\n",
    "    props_container = np.zeros((len(container), 5))\n",
    "    \n",
    "    for i, cnt in enumerate(container):\n",
    "        area = cv2.contourArea(cnt)\n",
    "        per = cv2.arcLength(cnt, True)\n",
    "        circ = 4 * np.pi * area / per ** 2\n",
    "        \n",
    "        min_rect_area = cv2.minAreaRect(cnt)\n",
    "        width = min_rect_area[1][0]\n",
    "        height = min_rect_area[1][1]\n",
    "        delta = (width * height) - area\n",
    "        propor = width / height if height > 0 else 0\n",
    "        \n",
    "        props = [area, per, circ, delta, propor]\n",
    "        props_container[i] = props\n",
    "        \n",
    "    return props_container\n",
    "\n",
    "def extracao_propriedades(imagem_otimizada):\n",
    "    \"\"\"\n",
    "    Extract properties from all objects in an optimized binary image.\n",
    "    \n",
    "    Args:\n",
    "        imagem_otimizada (np.array): Optimized binary image\n",
    "        \n",
    "    Returns:\n",
    "        np.array: Properties of all detected objects\n",
    "    \"\"\"\n",
    "    contours, _ = cv2.findContours(imagem_otimizada, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    container = list(contours)\n",
    "    return get_propriedades_container(container)\n",
    "\n",
    "def get_estatistica_propriedades(vetor_props):\n",
    "    \"\"\"Calculate mean and standard deviation of properties.\"\"\"\n",
    "    media_props = np.mean(vetor_props, axis=0)\n",
    "    desvio_props = np.std(vetor_props, axis=0)\n",
    "    return media_props, desvio_props"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5f21a4",
   "metadata": {},
   "source": [
    "## 4. Preparação da data de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a65902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize containers for each brick type\n",
    "container_2x2 = []\n",
    "container_2x4 = []\n",
    "container_2x6 = []\n",
    "container_2x8 = []\n",
    "container_undef = []\n",
    "\n",
    "def insert_in_container(img, container, contour_idx):\n",
    "    \"\"\"Add specific contours to a container.\"\"\"\n",
    "    contours = get_contours(img)\n",
    "    for i in contour_idx:\n",
    "        container.append(contours[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e89684",
   "metadata": {},
   "source": [
    "### Labeling Manual da data de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a8f285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image 0: \n",
    "# 2x2: [0,7,8], \n",
    "# 2x4: [2,4,5], \n",
    "# 2x8: [6], \n",
    "# Undef: [1,3]\n",
    "insert_in_container(DATA[0], container_2x2, [0, 7, 8])\n",
    "insert_in_container(DATA[0], container_2x4, [2, 4, 5])\n",
    "insert_in_container(DATA[0], container_2x8, [6])\n",
    "insert_in_container(DATA[0], container_undef, [1, 3])\n",
    "\n",
    "# Image 1: \n",
    "# 2x2: [4,5], \n",
    "# 2x4: [0,2], \n",
    "# 2x8: [3], \n",
    "# Undef: [1]\n",
    "insert_in_container(DATA[1], container_2x2, [4, 5])\n",
    "insert_in_container(DATA[1], container_2x4, [0, 2])\n",
    "insert_in_container(DATA[1], container_2x8, [3])\n",
    "insert_in_container(DATA[1], container_undef, [1])\n",
    "\n",
    "# Image 2: \n",
    "# 2x2: [0,2], \n",
    "# 2x4: [1]\n",
    "insert_in_container(DATA[2], container_2x2, [0, 2])\n",
    "insert_in_container(DATA[2], container_2x4, [1])\n",
    "\n",
    "# Image 3: \n",
    "# 2x4: [0,1], \n",
    "# 2x6: [2], \n",
    "# 2x8: [3]\n",
    "insert_in_container(DATA[3], container_2x4, [0, 1])\n",
    "insert_in_container(DATA[3], container_2x6, [2])\n",
    "insert_in_container(DATA[3], container_2x8, [3])\n",
    "\n",
    "# Image 4: \n",
    "# 2x4: [1], \n",
    "# 2x8: [2], \n",
    "# Undef: [0]\n",
    "insert_in_container(DATA[4], container_2x4, [1])\n",
    "insert_in_container(DATA[4], container_2x8, [2])\n",
    "insert_in_container(DATA[4], container_undef, [0])\n",
    "\n",
    "# Image 5: \n",
    "# 2x4: [0,2], \n",
    "# 2x8: [1]\n",
    "insert_in_container(DATA[5], container_2x4, [0, 2])\n",
    "insert_in_container(DATA[5], container_2x8, [1])\n",
    "\n",
    "# Image 6: \n",
    "# Undef: [0,1,2]\n",
    "insert_in_container(DATA[6], container_undef, [0, 1, 2])\n",
    "\n",
    "# Image 7: \n",
    "# 2x4: [0,1], \n",
    "# 2x6: [2], \n",
    "# Undef: [3]\n",
    "insert_in_container(DATA[7], container_2x4, [0, 1])\n",
    "insert_in_container(DATA[7], container_2x6, [2])\n",
    "insert_in_container(DATA[7], container_undef, [3])\n",
    "\n",
    "# Image 8: \n",
    "# 2x2: [0], \n",
    "# 2x4: [1], \n",
    "# 2x6: [2], \n",
    "# 2x8: [3]\n",
    "insert_in_container(DATA[8], container_2x2, [0])\n",
    "insert_in_container(DATA[8], container_2x4, [1])\n",
    "insert_in_container(DATA[8], container_2x6, [2])\n",
    "insert_in_container(DATA[8], container_2x8, [3])\n",
    "\n",
    "# Image 9: \n",
    "# 2x2: [0,1,2,3]\n",
    "insert_in_container(DATA[9], container_2x2, [0, 1, 2, 3])\n",
    "\n",
    "# Image 10: \n",
    "# 2x4: [0,1,2,3]\n",
    "insert_in_container(DATA[10], container_2x4, [0, 1, 2, 3])\n",
    "\n",
    "# Image 11: \n",
    "# 2x8: [0]\n",
    "insert_in_container(DATA[11], container_2x8, [0])\n",
    "\n",
    "# Image 12: \n",
    "# 2x2: [1], \n",
    "# 2x4: [0], \n",
    "# 2x6: [3,4], \n",
    "# Undef: [2]\n",
    "insert_in_container(DATA[12], container_2x2, [1])\n",
    "insert_in_container(DATA[12], container_2x4, [0])\n",
    "insert_in_container(DATA[12], container_2x6, [3, 4])\n",
    "insert_in_container(DATA[12], container_undef, [2])\n",
    "\n",
    "# Image 13: \n",
    "# 2x2: [1], \n",
    "# 2x4: [0], \n",
    "# 2x6: [4], \n",
    "# Undef: [2,3]\n",
    "insert_in_container(DATA[13], container_2x2, [1])\n",
    "insert_in_container(DATA[13], container_2x4, [0])\n",
    "insert_in_container(DATA[13], container_2x6, [4])\n",
    "insert_in_container(DATA[13], container_undef, [2, 3])\n",
    "\n",
    "print(f\"Training samples \\n2x2: {len(container_2x2)}, \\n2x4: {len(container_2x4)}, \"\n",
    "      f\"\\n2x6: {len(container_2x6)}, \\n2x8: {len(container_2x8)}, \\nUndefined: {len(container_undef)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e8d77b",
   "metadata": {},
   "source": [
    "### Calcular propriedades e estatísticas para cada classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a90f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate properties and statistics for each brick type\n",
    "props_2x2 = get_propriedades_container(container_2x2)\n",
    "media_2x2, desvio_2x2 = get_estatistica_propriedades(props_2x2)\n",
    "\n",
    "props_2x4 = get_propriedades_container(container_2x4)\n",
    "media_2x4, desvio_2x4 = get_estatistica_propriedades(props_2x4)\n",
    "\n",
    "props_2x6 = get_propriedades_container(container_2x6)\n",
    "media_2x6, desvio_2x6 = get_estatistica_propriedades(props_2x6)\n",
    "\n",
    "props_2x8 = get_propriedades_container(container_2x8)\n",
    "media_2x8, desvio_2x8 = get_estatistica_propriedades(props_2x8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ffe661",
   "metadata": {},
   "source": [
    "### Gráficos de Distribuição das propriedades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9e5cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "property_names = ['Area', 'Perimeter', 'Circularity', 'Delta', 'Proportion']\n",
    "\n",
    "for i in range(5):\n",
    "    plt.subplot(3, 2, i + 1)\n",
    "    plt.title(property_names[i], fontsize=12, fontweight='bold')\n",
    "    plt.hist(props_2x2[:, i], bins=15, alpha=0.5, label='2x2')\n",
    "    plt.hist(props_2x4[:, i], bins=15, alpha=0.5, label='2x4')\n",
    "    plt.hist(props_2x6[:, i], bins=15, alpha=0.5, label='2x6')\n",
    "    plt.hist(props_2x8[:, i], bins=15, alpha=0.5, label='2x8')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfff69f",
   "metadata": {},
   "source": [
    "## 5. Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684bf98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_based_classification(propriedades, debug=False, std_deviation_elimination=False, confidence_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Classify objects based on Euclidean distance to class means.\n",
    "    \n",
    "    Objects are classified as undefined if their distance exceeds\n",
    "    2 times the maximum standard deviation of the nearest class.\n",
    "    \n",
    "    Args:\n",
    "        propriedades (np.array): Array of object properties\n",
    "        \n",
    "    Returns:\n",
    "        np.array: Classification results [width, length] for each object\n",
    "    \"\"\"\n",
    "    results = np.zeros((len(propriedades), 2))\n",
    "    \n",
    "    desvio_dict = {\n",
    "        2: desvio_2x2,\n",
    "        4: desvio_2x4,\n",
    "        6: desvio_2x6,\n",
    "        8: desvio_2x8\n",
    "    }\n",
    "    \n",
    "    for i, vetor_prop in enumerate(propriedades):\n",
    "        # Calculate Euclidean distance to each class mean\n",
    "        distances = {\n",
    "            2: spd.euclidean(vetor_prop, media_2x2),\n",
    "            4: spd.euclidean(vetor_prop, media_2x4),\n",
    "            6: spd.euclidean(vetor_prop, media_2x6),\n",
    "            8: spd.euclidean(vetor_prop, media_2x8)\n",
    "        }\n",
    "        \n",
    "        # Find closest class\n",
    "        # predict_class = min(distances, key=distances.get)\n",
    "        sorted_dist = sorted(distances.items(), key=lambda x: x[1])\n",
    "        predict_class = sorted_dist[0][0]\n",
    "        second_closest_class = sorted_dist[1][0]\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"Object {i}: Distances {distances}, Predicted class: {predict_class}\")\n",
    "            print(f\"desvio_dict[predict_class].max() * 2: {desvio_dict[predict_class].max() * 2}\")\n",
    "            print(f\"Confidence threshold: {confidence_threshold * distances[predict_class]}\")\n",
    "            print(f\"distances[second_closest_class] - distances[predict_class]: {distances[second_closest_class] - distances[predict_class]}\")\n",
    "            \n",
    "        # Verificar se distancia excede o desvio padrão por duas vezes (Se std_deviation_elimination=True)\n",
    "        if (distances[predict_class] > desvio_dict[predict_class].max() * 2) and std_deviation_elimination:\n",
    "            predict_class = 0\n",
    "        # Eliminar classificações com baixa confiança\n",
    "        elif distances[second_closest_class] - distances[predict_class] < confidence_threshold * distances[predict_class]:\n",
    "            predict_class = 0\n",
    "            \n",
    "        results[i] = np.array([2, predict_class])\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfebeda",
   "metadata": {},
   "source": [
    "## 6. Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad960f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_classify(image, tolerance=110, show_images=True, debug=False, std_deviation_elimination=False, confidence_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Complete pipeline: preprocess, optimize, extract features, and classify.\n",
    "    \n",
    "    Args:\n",
    "        image (np.array): Input BGR image\n",
    "        tolerance (int): Tolerance for binarization\n",
    "        show_images (bool): Whether to display intermediate results\n",
    "        \n",
    "    Returns:\n",
    "        np.array: Classification results\n",
    "    \"\"\"\n",
    "    # Preprocessing\n",
    "    image_objects, bin_image = binarizacao(image, tolerance)\n",
    "    image_opt = optimize_image(bin_image)\n",
    "    \n",
    "    # Feature extraction and classification\n",
    "    propriedades = extracao_propriedades(image_opt)\n",
    "    resultados = distance_based_classification(propriedades, debug=debug, std_deviation_elimination=std_deviation_elimination, confidence_threshold=confidence_threshold)\n",
    "    \n",
    "    # Display results if requested\n",
    "    if show_images:\n",
    "        showImages([image, image_objects, bin_image, image_opt],\n",
    "                  [\"Original\", \"No Background\", \"Binary\", \"Optimized\"])\n",
    "    \n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0533340",
   "metadata": {},
   "source": [
    "### Teste 1: Imagem 7\n",
    "Expected: [2x4, 2x4, 2x6, Undefined]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72035e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Case 1 - Image 7\")\n",
    "print(\"Expected: 2x4, 2x4, 2x6, Undefined\")\n",
    "resultados_teste1 = process_and_classify(DATA[7], show_images=False, debug=False, std_deviation_elimination=True, confidence_threshold=0.5)\n",
    "print(\"Results:\")\n",
    "print(resultados_teste1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18553ec5",
   "metadata": {},
   "source": [
    "### Teste 2: Imagem 4\n",
    "Expected: [Undefined, 2x4, 2x8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c0c1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Case 2 - Image 4\")\n",
    "print(\"Expected: Undefined, 2x4, 2x8\")\n",
    "resultados_teste2 = process_and_classify(DATA[4], show_images=False, debug=False, std_deviation_elimination=True, confidence_threshold=0.5)\n",
    "print(\"Results:\")\n",
    "print(resultados_teste2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67592116",
   "metadata": {},
   "source": [
    "### Teste 3: Imagem 0\n",
    "Expected: [2x2, Undefined, 2x4, Undefined, 2x4, 2x4, 2x8, 2x2, 2x2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40807c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Case 3 - Image 0\")\n",
    "print(\"Expected: 2x2, Undefined, 2x4, Undefined, 2x4, 2x4, 2x8, 2x2, 2x2\")\n",
    "resultados_teste3 = process_and_classify(DATA[0], show_images=False, debug=False, std_deviation_elimination=True, confidence_threshold=0.5)\n",
    "print(\"Results:\")\n",
    "print(resultados_teste3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ab3339",
   "metadata": {},
   "source": [
    "### Teste 4: Imagem 3\n",
    "Expected: [2x4, 2x4, 2x6, 2x8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d28e2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Case 4 - Image 3\")\n",
    "print(\"Expected: 2x4, 2x4, 2x6, 2x8\")\n",
    "resultados_teste4 = process_and_classify(DATA[3], show_images=False, debug=False, std_deviation_elimination=True, confidence_threshold=0.5)\n",
    "print(\"Results:\")\n",
    "print(resultados_teste4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c16499",
   "metadata": {},
   "source": [
    "### Teste 5: Imagem 12\n",
    "Expected: [2x4, 2x2, Undefined, 2x6, 2x6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903005de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Case 5 - Image 12\")\n",
    "print(\"Expected: 2x4, 2x2, Undefined, 2x6, 2x6\")\n",
    "resultados_teste5 = process_and_classify(DATA[12], show_images=False, debug=False, std_deviation_elimination=True, confidence_threshold=0.1)\n",
    "print(\"Results:\")\n",
    "print(resultados_teste5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
